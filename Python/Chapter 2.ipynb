{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7984c88b-75c1-476b-a70f-7046e99fc09a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Consider PyStan is you ever move off Databricks and want to stay with Pyton. #\n",
    "################################################################################\n",
    "# %pip install PyPI cmdstanpy\n",
    "# %pip install pymc\n",
    "# dbutils.library.restartPython()\n",
    "# %pip list\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import beta, binom, uniform\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# 2.1 p.27\n",
    "ways = [0, 3, 8, 9, 0]\n",
    "[item / sum(ways) for item in ways]\n",
    "\n",
    "# 2.2 p.33\n",
    "binom.pmf(6, 9, 0.6667)\n",
    "\n",
    "###########################\n",
    "# Grid Approximation p.39 #\n",
    "###########################\n",
    "# 2.3 p.40\n",
    "# define grid\n",
    "p_grid = np.linspace(start=0, stop=1, num=20)\n",
    "# define prior\n",
    "prior = np.repeat(1, 20)\n",
    "# compute likelihood as each value in grid\n",
    "likelihood = binom.pmf(6, 9, p_grid)\n",
    "# compute product of likelihood and prior\n",
    "unstd_posterior = likelihood * prior\n",
    "# standardize the posterior, so it sums to 1\n",
    "posterior = unstd_posterior / sum(unstd_posterior)\n",
    "# 2.4 p.40\n",
    "plt.plot(p_grid, posterior, linestyle='-', marker='o')\n",
    "plt.xlabel('probability of water')\n",
    "plt.ylabel('posterior probability')\n",
    "plt.title('100 points')\n",
    "plt.show()\n",
    "# 2.5 p.40 \n",
    "p_grid = np.linspace(start=0, stop=1, num=100)\n",
    "prior = np.where(p_grid < 0.5, 0, 1)\n",
    "likelihood = binom.pmf(6, 9, p_grid)\n",
    "unstd_posterior = likelihood * prior\n",
    "posterior = unstd_posterior / sum(unstd_posterior)\n",
    "plt.plot(p_grid, posterior, linestyle='-', marker='o')\n",
    "plt.xlabel('probability of water')\n",
    "plt.ylabel('posterior probability')\n",
    "plt.title('100 points')\n",
    "plt.show()\n",
    "p_grid = np.linspace(start=0, stop=1, num=100)\n",
    "prior = np.exp(-5 * abs(p_grid - 0.5 ))\n",
    "likelihood = binom.pmf(6, 9, p_grid)\n",
    "unstd_posterior = likelihood * prior\n",
    "posterior = unstd_posterior / sum(unstd_posterior)\n",
    "plt.plot(p_grid, posterior, linestyle='-', marker='o')\n",
    "plt.xlabel('probability of water')\n",
    "plt.ylabel('posterior probability')\n",
    "plt.title('100 points')\n",
    "plt.show()\n",
    "################################\n",
    "# Quadratic Approximation p.41 #\n",
    "################################\n",
    "# 2.5 p.42 Quadratic Approximation\n",
    "data = np.repeat((0,1), (6,12)) # 9 tosses, three L (0), six water (1). Also try 18 and 36 tosses.\n",
    "with pm.Model() as normal_approx:\n",
    "  p = pm.Uniform('p', 0, 1) # uniform prior\n",
    "  w = pm.Binomial('w', n=len(data), p=p, observed=data.sum()) #binomial likelihood\n",
    "  mean_q = pm.find_MAP() # find local maximum a posteriori with this model\n",
    "  normal_approx.rvs_to_transforms[p] = None # remove transform from the variable `p`\n",
    "  p_value = normal_approx.rvs_to_values[p]\n",
    "  p_value.name = p.name # change name so that we can use `mean_q[\"p\"]` value\n",
    "  std_q = ((1/pm.find_hessian(mean_q, vars=[p]))**0.5)[0] # find the standard deviation\n",
    "mean_q['p'], std_q\n",
    "prob = 0.89\n",
    "z = stats.norm.ppf([(1-prob)/2, (1+prob)/2])\n",
    "perc = mean_q[\"p\"]+std_q*z\n",
    "print('Summary of quadratic approximation: mean {0:.2f}, StdDev {1:.2f}, 5.5% CI {2:.2f}, 94.5% CI {3:.2f}'.format(mean_q[\"p\"], std_q[0], perc[0], perc[1]))\n",
    "# 2.6 p.43 Analytical Calculation\n",
    "w = 12 # try values of 6, 12, 24\n",
    "n = 18 # try values of 9, 18, 36\n",
    "x = np.arange(0, 1, 0.01) # create an x arrary for beta function calc\n",
    "plt.plot(x, stats.beta.pdf(x, w+1, n-w+1), '--', label='true')\n",
    "plt.plot(x, stats.norm.pdf(x, mean_q[\"p\"], std_q[0]), label='Quadratic Appx.')\n",
    "plt.title('n=9')\n",
    "plt.xlabel('proportion of water')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Course Video https://www.youtube.com/watch?v=R1vcdhPBlXA\n",
    "# function to toss a globe covered p by water N times\n",
    "def sim_globe(p=0.7, N=9) : \n",
    "  return np.random.choice([\"W\",\"L\"], size=N, p=[p, 1-p])\n",
    "sim_globe()\n",
    "results = pd.DataFrame([sim_globe() for _ in range(10)]) # run 10 simulations\n",
    "display(results)\n",
    "# test your code\n",
    "sim_globe(p=1, N=11) # check that your code produces all water with probability of water equals 100%\n",
    "sum(np.array(sim_globe(p=0.5, N=int(1e4))) == \"W\") / 1e4 # check that your code produces simulated results of 50% water\n",
    "# function to compute posterior distribution\n",
    "def compute_posterior(the_sample, poss=[0, 0.25, 0.5, 0.75, 1]) : \n",
    "  the_sample = np.array(the_sample)\n",
    "  W = np.sum(the_sample == \"W\") # number of W observed\n",
    "  L = np.sum(the_sample == \"L\") # number of L observed\n",
    "  ways = np.array([((x*4)**W)*(((1-x)*4)**L) for x in poss])\n",
    "  post = ways/np.sum(ways)\n",
    "  df = pd.DataFrame({\"poss\":poss, \"ways\":[str(w) for w in ways], \"post\":np.round(post,3)})\n",
    "  return df\n",
    "print(compute_posterior(sim_globe()))\n",
    "# simulate posterior predictive distribution\n",
    "post_samples = beta.rvs(a=6+1, b=3+1, size=10000)\n",
    "pred_post = [np.sum(sim_globe(p, 10) == \"W\") for p in post_samples]\n",
    "pred_spec = [np.sum(sim_globe(0.71, 10) == \"W\") for _ in post_samples]\n",
    "tab_post = pd.Series(pred_post).value_counts().sort_index()\n",
    "tab_spec = pd.Series(pred_spec).value_counts().sort_index()\n",
    "plt.bar(tab_spec.index, tab_spec, color='black', width=0.6, label = 'specific predictive')\n",
    "plt.bar(tab_post.index, tab_post, color='blue', width=0.2, label ='posterior predictive')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('number of W')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n",
    "# misclassification simulation\n",
    "def sim_globe_miscls(p=0.71, N=10, x=0.1) :\n",
    "  true_sample = np.random.choice([\"W\",\"L\"], size=N, p=[p, 1-p])\n",
    "  obs_sample = np.array([(\"L\" if ts == \"W\" else \"W\") if random.random() < x else ts for ts in true_sample])\n",
    "  return obs_sample\n",
    "pred_err_post = [np.sum(sim_globe_miscls(p, 10, 0.1) == \"W\") for p in post_samples]\n",
    "tab_err_post = pd.Series(pred_err_post).value_counts().sort_index()\n",
    "plt.plot(tab_spec.index, tab_spec.values, label='previous posterior', color='black', linewidth=4)\n",
    "plt.plot(tab_err_post.index, tab_err_post.values, label='misclassification posterior\\nerror rate 10%', color='red', linewidth=4)\n",
    "plt.xlabel(\"proportion of water\")\n",
    "plt.ylabel(\"posterior probability\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Chapter 2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
